name: CI .
on: [push]
      # The release versions will be verified by 'publish-release.yml'

concurrency:
  # Cancel the previous builds in the same PR.
  # Allow running concurrently for all non-PR commits.
  group: ci-${{ github.event.pull_request.number || github.sha }}
  cancel-in-progress: true

env:
  LC_ALL: "en_US.UTF-8"

jobs:
  build:
    if: github.repository == 'line/armeria'
    runs-on: ${{ matrix.on }}
    timeout-minutes: 80
    strategy:
      fail-fast: false
      matrix:
        on: [push]
        java: [ 17 ]
        include:
          - java: 8
            on: [push]
          - java: 11
            on: [push]
          - java: 16
            on: [push]
            leak: true
          - java: 17
            # TODO(ikhoon): Revert to self-hosted runners once the following error is fixed
            #               `Cannot expand ZIP '/actions-runner/../armeria-shaded-1.7.3-SNAPSHOT.jar' as it does not exist.`
            on: [push]
            coverage: true
          - java: 17
            on: [push]
            snapshot: true

    steps:
      - uses: actions/setup-python@v2
        with:
          python-version: '3.10'
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas
          pip install numpy
      - run: sudo apt update
      - run: sudo apt install inotify-tools
      - run: inotifywait -mr /home/runner/work --format '%T;%w;%f;%e' --timefmt %T -o /home/runner/test.csv & echo 'basak'
      - uses: jannekem/run-python-script-action@v1
        with:
          script: |
            import pandas as pd
            import numpy as np
            df = pd.read_csv('/home/runner/test.csv', sep = ';', names=['time', 'watched_filename', 'event_filename', 'event_name'])
            df['event_filename'] = df['event_filename'].replace(np.nan, '')
            steps = {}
            starting_indexes = df[(df['event_filename'].str.contains('starting_')) & (df['event_name'] == 'CREATE')].index.to_list() + [df.shape[0]]
            ending_indexes = [0] + df[(df['event_filename'].str.contains('starting_')) & (df['event_name'] == 'CLOSE_WRITE,CLOSE')].index.to_list()
            starting_df = df[df['event_filename'].str.contains('starting_')]
            touch_file_names = ['setup'] + [x.replace('starting_', '') for x in starting_df['event_filename'].value_counts().index.to_list()]
            for starting_index, ending_index, touch_file_name in zip(starting_indexes, ending_indexes, touch_file_names):
                steps[touch_file_name] = (ending_index, starting_index)
            df['watched_filename'] = df['watched_filename'] + df['event_filename']
            df.drop('event_filename', axis=1, inplace=True)
            df.rename(columns={'watched_filename':'file_name'}, inplace=True)
            modify_df = df[df['event_name'] == 'MODIFY']
            file_names = modify_df['file_name'].value_counts().index.to_list()
            info = []
            for file_name in file_names:
                last_access_step = ''
                last_modify_step = ''
                creation_step = ''
                if df[(df['file_name'] == file_name) & (df['event_name'] == 'MODIFY')].shape[0] == 0: continue
                last_modify_index = df[(df['file_name'] == file_name) & (df['event_name'] == 'MODIFY')].index.to_list()[-1]
                last_access_index = 0
                if df[(df['file_name'] == file_name) & (df['event_name'] == 'ACCESS')].shape[0] > 0:
                    last_access_index = df[(df['file_name'] == file_name) & (df['event_name'] == 'ACCESS')].index.to_list()[-1]
                else:
                    last_access_index = -1
                    last_access_step = 'Not provided'
                if last_access_index < last_modify_index:
                    try:
                        creation_index = df[(df['file_name'] == file_name) & (df['event_name'] == 'CREATE')].index.to_list()[0]
                    except:
                        creation_index = -1
                        creation_step = 'Not provided'
                    for touch_file_name, (starting_index, ending_index) in steps.items():
                        if (last_access_index > starting_index) & (last_access_index < ending_index):
                            last_access_step = touch_file_name if touch_file_name == 'setup' else touch_file_name.split('_')[1]
                        if (last_modify_index > starting_index) & (last_modify_index < ending_index):
                            last_modify_step = touch_file_name if touch_file_name == 'setup' else touch_file_name.split('_')[1]
                        if (creation_index > starting_index) & (creation_index < ending_index):
                            creation_step = touch_file_name if touch_file_name == 'setup' else touch_file_name.split('_')[1]
                    info.append({'file_name': file_name, 'last_access_index': last_access_index, 'last_modify_index': last_modify_index, 'creation_index': creation_index, 'last_access_step':last_access_step , 'last_modify_step':last_modify_step, 'creation_step': creation_step})
            info_df = pd.DataFrame(info)
            info_df.to_csv('/home/runner/info.csv')
            os.mkdir('optimizing-ci-builds-ci-analysis')
            info_df.to_csv('/home/runner/work/armeria/armeria/optimizing-ci-builds-ci-analysis/analysis.csv')
      - name: Pushes analysis to another repository
        id: push_directory
        uses: cpina/github-action-push-to-another-repository@main
        env:
          API_TOKEN_GITHUB: ${{ secrets.API_TOKEN_GITHUB }}
        with:
          source-directory: 'optimizing-ci-builds-ci-analysis'
          destination-github-username: 'optimizing-ci-builds'
          destination-repository-name: 'ci-analyzes'
          target-directory: 'armeria/.github/workflows/actions_build/build'
      - run: touch starting_build_actionscheckout@v2_48
      - uses: actions/checkout@v2

      - id: setup-jdk
        if: ${{ matrix.java != 17 }}
        name: Set up JDK ${{ matrix.java }}
        uses: actions/setup-java@v2
        with:
          distribution: 'temurin'
          java-version: ${{ matrix.java }}

      - id: setup-jdk-17
        name: Set up JDK 17
        uses: actions/setup-java@v2
        with:
          distribution: 'temurin'
          java-version: '17'

      - if: ${{ matrix.on != 'self-hosted' }}
        name: Restore the cache
        uses: actions/cache@v2
        with:
          path: |
            ~/.gradle/wrapper
            ~/.gradle/caches
          key: build-${{ matrix.java }}-${{ runner.os }}-${{ secrets.CACHE_VERSION }}-${{ hashFiles('gradle.properties', 'gradle/wrapper/gradle-wrapper.properties', '**/build.gradle', 'dependencies.yml', '*/package-lock.json') }}
          restore-keys: |
            build-${{ matrix.java }}-${{ runner.os }}-${{ secrets.CACHE_VERSION }}-
            build-${{ matrix.java }}-${{ runner.os }}-

      # Build the shaded JARs first so that shading process doesn't incur memory pressure
      # on other Gradle tasks such as tests.
      - run: touch starting_build_BuildwithGradle(Shadingonly)_79
      - name: Build with Gradle (Shading only)
        run: |
          ./gradlew --no-daemon --stacktrace shadedJar shadedTestJar trimShadedJar \
          ${{ (matrix.on == 'self-hosted') && '--max-workers=8' || '--max-workers=2' }} --parallel \
          ${{ matrix.coverage && '-Pcoverage' || '' }} \
          -PnoLint \
          -PbuildJdkVersion=17 \
          -PtestJavaVersion=${{ matrix.java }} \
          -Porg.gradle.java.installations.paths=${{ steps.setup-jdk-17.outputs.path }},${{ steps.setup-jdk.outputs.path }}
        shell: bash

      - run: touch starting_build_BuildwithGradle_90
      - name: Build with Gradle
        run: |
          ./gradlew --no-daemon --stacktrace build \
          ${{ (matrix.on == 'self-hosted') && '--max-workers=8' || '--max-workers=2' }} --parallel \
          ${{ matrix.coverage && '-Pcoverage' || '' }} \
          ${{ matrix.leak && '-Pleak' || '' }} \
          -PnoLint \
          -PflakyTests=false \
          -PbuildJdkVersion=17 \
          -PtestJavaVersion=${{ matrix.java }} \
          -Porg.gradle.java.installations.paths=${{ steps.setup-jdk-17.outputs.path }},${{ steps.setup-jdk.outputs.path }}
        shell: bash

      - if: ${{ matrix.snapshot && github.ref_name == 'master' }}
        name: Publish snapshots
        run: |
          ./gradlew --no-daemon --stacktrace --max-workers=1 publish
        env:
          # Should not use '-P' option with 'secrets' that can cause unexpected results
          # if secret values contains white spaces or new lines.
          ORG_GRADLE_PROJECT_ossrhUsername: ${{ secrets.OSSRH_USER_NAME }}
          ORG_GRADLE_PROJECT_ossrhPassword: ${{ secrets.OSSRH_PASSWORD }}
          ORG_GRADLE_PROJECT_signingKeyId: ${{ secrets.GPG_KEY_ID }}
          ORG_GRADLE_PROJECT_signingKey: ${{ secrets.GPG_PRIVATE_KEY }}
          ORG_GRADLE_PROJECT_signingPassword: ${{ secrets.GPG_PASSWORD }}
        shell: bash

      - run: touch starting_build_Summarizethefailedtests_117
      - name: Summarize the failed tests
        if: failure()
        run: |
          ./gradlew --no-daemon --stacktrace --max-workers=1 reportFailedTests \
          -PnoLint \
          -PflakyTests=false \
          -PbuildJdkVersion=17 \
          -PtestJavaVersion=${{ matrix.java }} \
          -Porg.gradle.java.installations.paths=${{ steps.setup-jdk-17.outputs.path }},${{ steps.setup-jdk.outputs.path }}
          
          SUMMARY_FILE="build/failed-tests-result.txt"
          if test -f "$SUMMARY_FILE"; then
            echo '### ðŸ”´ Failed tests' >> $GITHUB_STEP_SUMMARY
            cat $SUMMARY_FILE >> $GITHUB_STEP_SUMMARY
          fi
        shell: bash

      - run: touch starting_build_Cleanupthecache_134
      - name: Clean up the cache
        # Remove some files from the Gradle cache, so they aren't cached by GitHub Actions.
        # Restoring these files from a GitHub Actions cache might cause problems for future builds.
        run: |
          rm -fr ~/.gradle/caches/[0-9]* || true
          rm -fr ~/.gradle/caches/journal-* || true
          rm -fr ~/.gradle/caches/transforms-* || true
          rm -f ~/.gradle/caches/*/*.lock || true
          rm -f ~/.gradle/caches/*/gc.properties || true
        shell: bash

      - run: touch starting_build_Dumpstuckthreads_145
      - name: Dump stuck threads
        if: always()
        run: jps | grep -vi "jps" | awk '{ print $1 }' | xargs -I'{}' jstack -l {} || true
        shell: bash

      - run: touch starting_build_UploadthecoveragereporttoCodecov_150
      - name: Upload the coverage report to Codecov
        if: ${{ matrix.coverage }}
        uses: codecov/codecov-action@v1

      - run: touch starting_build_Collectthetestreports_154
      - name: Collect the test reports
        if: failure()
        run: find . '(' -name 'java_pid*.hprof' -or -name 'hs_err_*.log' -or -path '*/build/reports/tests' -or -path '*/build/test-results' ')' -exec tar rf "reports-JVM-${{ matrix.java }}.tar" {} ';'
        shell: bash

      - run: touch starting_build_Uploadtheartifacts_159
      - name: Upload the artifacts
        if: failure()
        uses: actions/upload-artifact@v2
        with:
          name: reports-JVM-${{ matrix.java }}
          path: reports-JVM-${{ matrix.java }}.tar
          retention-days: 3

  lint:
    if: github.repository == 'line/armeria'
    runs-on: self-hosted
    timeout-minutes: 60
    steps:
      - uses: actions/setup-python@v2
        with:
          python-version: '3.10'
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas
          pip install numpy
      - run: sudo apt update
      - run: sudo apt install inotify-tools
      - run: inotifywait -mr /home/runner/work --format '%T;%w;%f;%e' --timefmt %T -o /home/runner/test.csv & echo 'basak'
      - uses: jannekem/run-python-script-action@v1
        with:
          script: |
            import pandas as pd
            import numpy as np
            df = pd.read_csv('/home/runner/test.csv', sep = ';', names=['time', 'watched_filename', 'event_filename', 'event_name'])
            df['event_filename'] = df['event_filename'].replace(np.nan, '')
            steps = {}
            starting_indexes = df[(df['event_filename'].str.contains('starting_')) & (df['event_name'] == 'CREATE')].index.to_list() + [df.shape[0]]
            ending_indexes = [0] + df[(df['event_filename'].str.contains('starting_')) & (df['event_name'] == 'CLOSE_WRITE,CLOSE')].index.to_list()
            starting_df = df[df['event_filename'].str.contains('starting_')]
            touch_file_names = ['setup'] + [x.replace('starting_', '') for x in starting_df['event_filename'].value_counts().index.to_list()]
            for starting_index, ending_index, touch_file_name in zip(starting_indexes, ending_indexes, touch_file_names):
                steps[touch_file_name] = (ending_index, starting_index)
            df['watched_filename'] = df['watched_filename'] + df['event_filename']
            df.drop('event_filename', axis=1, inplace=True)
            df.rename(columns={'watched_filename':'file_name'}, inplace=True)
            modify_df = df[df['event_name'] == 'MODIFY']
            file_names = modify_df['file_name'].value_counts().index.to_list()
            info = []
            for file_name in file_names:
                last_access_step = ''
                last_modify_step = ''
                creation_step = ''
                if df[(df['file_name'] == file_name) & (df['event_name'] == 'MODIFY')].shape[0] == 0: continue
                last_modify_index = df[(df['file_name'] == file_name) & (df['event_name'] == 'MODIFY')].index.to_list()[-1]
                last_access_index = 0
                if df[(df['file_name'] == file_name) & (df['event_name'] == 'ACCESS')].shape[0] > 0:
                    last_access_index = df[(df['file_name'] == file_name) & (df['event_name'] == 'ACCESS')].index.to_list()[-1]
                else:
                    last_access_index = -1
                    last_access_step = 'Not provided'
                if last_access_index < last_modify_index:
                    try:
                        creation_index = df[(df['file_name'] == file_name) & (df['event_name'] == 'CREATE')].index.to_list()[0]
                    except:
                        creation_index = -1
                        creation_step = 'Not provided'
                    for touch_file_name, (starting_index, ending_index) in steps.items():
                        if (last_access_index > starting_index) & (last_access_index < ending_index):
                            last_access_step = touch_file_name if touch_file_name == 'setup' else touch_file_name.split('_')[1]
                        if (last_modify_index > starting_index) & (last_modify_index < ending_index):
                            last_modify_step = touch_file_name if touch_file_name == 'setup' else touch_file_name.split('_')[1]
                        if (creation_index > starting_index) & (creation_index < ending_index):
                            creation_step = touch_file_name if touch_file_name == 'setup' else touch_file_name.split('_')[1]
                    info.append({'file_name': file_name, 'last_access_index': last_access_index, 'last_modify_index': last_modify_index, 'creation_index': creation_index, 'last_access_step':last_access_step , 'last_modify_step':last_modify_step, 'creation_step': creation_step})
            info_df = pd.DataFrame(info)
            info_df.to_csv('/home/runner/info.csv')
            os.mkdir('optimizing-ci-builds-ci-analysis')
            info_df.to_csv('/home/runner/work/armeria/armeria/optimizing-ci-builds-ci-analysis/analysis.csv')
      - name: Pushes analysis to another repository
        id: push_directory
        uses: cpina/github-action-push-to-another-repository@main
        env:
          API_TOKEN_GITHUB: ${{ secrets.API_TOKEN_GITHUB }}
        with:
          source-directory: 'optimizing-ci-builds-ci-analysis'
          destination-github-username: 'optimizing-ci-builds'
          destination-repository-name: 'ci-analyzes'
          target-directory: 'armeria/.github/workflows/actions_build/lint'
      - run: touch starting_lint_actionscheckout@v2_172
      - uses: actions/checkout@v2

      - id: setup-jdk-17
        name: Set up JDK 17
        uses: actions/setup-java@v2
        with:
          distribution: 'temurin'
          java-version: '17'

      - run: touch starting_lint_Runthelinters_181
      - name: Run the linters
        run: |
          ./gradlew --no-daemon --stacktrace --max-workers=8 --parallel lint

      - run: touch starting_lint_Cleanupthecache_185
      - name: Clean up the cache
        run: |
          rm -fr ~/.gradle/caches/[0-9]* || true
          rm -fr ~/.gradle/caches/journal-* || true
          rm -fr ~/.gradle/caches/transforms-* || true
          rm -f ~/.gradle/caches/*/*.lock || true
          rm -f ~/.gradle/caches/*/gc.properties || true
        shell: bash

  site:
    if: github.repository == 'line/armeria'
    # ubuntu-latest is preferred for site job.
    # node_modules need complicated dependencies that are difficult to install on self-hosted runners.
    runs-on: ubuntu-latest
    timeout-minutes: 60
    steps:
      - uses: actions/setup-python@v2
        with:
          python-version: '3.10'
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas
          pip install numpy
      - run: sudo apt update
      - run: sudo apt install inotify-tools
      - run: inotifywait -mr /home/runner/work --format '%T;%w;%f;%e' --timefmt %T -o /home/runner/test.csv & echo 'basak'
      - uses: jannekem/run-python-script-action@v1
        with:
          script: |
            import pandas as pd
            import numpy as np
            df = pd.read_csv('/home/runner/test.csv', sep = ';', names=['time', 'watched_filename', 'event_filename', 'event_name'])
            df['event_filename'] = df['event_filename'].replace(np.nan, '')
            steps = {}
            starting_indexes = df[(df['event_filename'].str.contains('starting_')) & (df['event_name'] == 'CREATE')].index.to_list() + [df.shape[0]]
            ending_indexes = [0] + df[(df['event_filename'].str.contains('starting_')) & (df['event_name'] == 'CLOSE_WRITE,CLOSE')].index.to_list()
            starting_df = df[df['event_filename'].str.contains('starting_')]
            touch_file_names = ['setup'] + [x.replace('starting_', '') for x in starting_df['event_filename'].value_counts().index.to_list()]
            for starting_index, ending_index, touch_file_name in zip(starting_indexes, ending_indexes, touch_file_names):
                steps[touch_file_name] = (ending_index, starting_index)
            df['watched_filename'] = df['watched_filename'] + df['event_filename']
            df.drop('event_filename', axis=1, inplace=True)
            df.rename(columns={'watched_filename':'file_name'}, inplace=True)
            modify_df = df[df['event_name'] == 'MODIFY']
            file_names = modify_df['file_name'].value_counts().index.to_list()
            info = []
            for file_name in file_names:
                last_access_step = ''
                last_modify_step = ''
                creation_step = ''
                if df[(df['file_name'] == file_name) & (df['event_name'] == 'MODIFY')].shape[0] == 0: continue
                last_modify_index = df[(df['file_name'] == file_name) & (df['event_name'] == 'MODIFY')].index.to_list()[-1]
                last_access_index = 0
                if df[(df['file_name'] == file_name) & (df['event_name'] == 'ACCESS')].shape[0] > 0:
                    last_access_index = df[(df['file_name'] == file_name) & (df['event_name'] == 'ACCESS')].index.to_list()[-1]
                else:
                    last_access_index = -1
                    last_access_step = 'Not provided'
                if last_access_index < last_modify_index:
                    try:
                        creation_index = df[(df['file_name'] == file_name) & (df['event_name'] == 'CREATE')].index.to_list()[0]
                    except:
                        creation_index = -1
                        creation_step = 'Not provided'
                    for touch_file_name, (starting_index, ending_index) in steps.items():
                        if (last_access_index > starting_index) & (last_access_index < ending_index):
                            last_access_step = touch_file_name if touch_file_name == 'setup' else touch_file_name.split('_')[1]
                        if (last_modify_index > starting_index) & (last_modify_index < ending_index):
                            last_modify_step = touch_file_name if touch_file_name == 'setup' else touch_file_name.split('_')[1]
                        if (creation_index > starting_index) & (creation_index < ending_index):
                            creation_step = touch_file_name if touch_file_name == 'setup' else touch_file_name.split('_')[1]
                    info.append({'file_name': file_name, 'last_access_index': last_access_index, 'last_modify_index': last_modify_index, 'creation_index': creation_index, 'last_access_step':last_access_step , 'last_modify_step':last_modify_step, 'creation_step': creation_step})
            info_df = pd.DataFrame(info)
            info_df.to_csv('/home/runner/info.csv')
            os.mkdir('optimizing-ci-builds-ci-analysis')
            info_df.to_csv('/home/runner/work/armeria/armeria/optimizing-ci-builds-ci-analysis/analysis.csv')
      - name: Pushes analysis to another repository
        id: push_directory
        uses: cpina/github-action-push-to-another-repository@main
        env:
          API_TOKEN_GITHUB: ${{ secrets.API_TOKEN_GITHUB }}
        with:
          source-directory: 'optimizing-ci-builds-ci-analysis'
          destination-github-username: 'optimizing-ci-builds'
          destination-repository-name: 'ci-analyzes'
          target-directory: 'armeria/.github/workflows/actions_build/site'
      - run: touch starting_site_actionscheckout@v2_201
      - uses: actions/checkout@v2

      - run: touch starting_site_Installsvgbob_cli_203
      - name: Install svgbob_cli
        run: |
          sudo apt-get -y install cargo && cargo install svgbob_cli
          echo "$HOME/.cargo/bin" >> $GITHUB_PATH

      - id: setup-jdk-17
        name: Set up JDK 17
        uses: actions/setup-java@v2
        with:
          distribution: 'temurin'
          java-version: '17'

      - run: touch starting_site_Restorethecache_215
      - name: Restore the cache
        uses: actions/cache@v2
        with:
          path: |
            ~/.gradle/wrapper
            ~/.gradle/caches
          key: build-${{ matrix.java }}-${{ runner.os }}-${{ secrets.CACHE_VERSION }}-${{ hashFiles('gradle.properties', 'gradle/wrapper/gradle-wrapper.properties', '**/build.gradle', 'dependencies.yml', '*/package-lock.json') }}
          restore-keys: |
            build-${{ matrix.java }}-${{ runner.os }}-${{ secrets.CACHE_VERSION }}-
            build-${{ matrix.java }}-${{ runner.os }}-

      - run: touch starting_site_Buildthesite_226
      - name: Build the site
        run: |
          ./gradlew --no-daemon --stacktrace  --max-workers=2 --parallel site
        shell: bash

      - run: touch starting_site_Cleanupthecache_231
      - name: Clean up the cache
        run: |
          rm -fr ~/.gradle/caches/[0-9]* || true
          rm -fr ~/.gradle/caches/journal-* || true
          rm -fr ~/.gradle/caches/transforms-* || true
          rm -f ~/.gradle/caches/*/*.lock || true
          rm -f ~/.gradle/caches/*/gc.properties || true
        shell: bash

  flaky-tests:
    if: github.repository == 'line/armeria'
    runs-on: self-hosted
    timeout-minutes: 60
    steps:
      - uses: actions/setup-python@v2
        with:
          python-version: '3.10'
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas
          pip install numpy
      - run: sudo apt update
      - run: sudo apt install inotify-tools
      - run: inotifywait -mr /home/runner/work --format '%T;%w;%f;%e' --timefmt %T -o /home/runner/test.csv & echo 'basak'
      - uses: jannekem/run-python-script-action@v1
        with:
          script: |
            import pandas as pd
            import numpy as np
            df = pd.read_csv('/home/runner/test.csv', sep = ';', names=['time', 'watched_filename', 'event_filename', 'event_name'])
            df['event_filename'] = df['event_filename'].replace(np.nan, '')
            steps = {}
            starting_indexes = df[(df['event_filename'].str.contains('starting_')) & (df['event_name'] == 'CREATE')].index.to_list() + [df.shape[0]]
            ending_indexes = [0] + df[(df['event_filename'].str.contains('starting_')) & (df['event_name'] == 'CLOSE_WRITE,CLOSE')].index.to_list()
            starting_df = df[df['event_filename'].str.contains('starting_')]
            touch_file_names = ['setup'] + [x.replace('starting_', '') for x in starting_df['event_filename'].value_counts().index.to_list()]
            for starting_index, ending_index, touch_file_name in zip(starting_indexes, ending_indexes, touch_file_names):
                steps[touch_file_name] = (ending_index, starting_index)
            df['watched_filename'] = df['watched_filename'] + df['event_filename']
            df.drop('event_filename', axis=1, inplace=True)
            df.rename(columns={'watched_filename':'file_name'}, inplace=True)
            modify_df = df[df['event_name'] == 'MODIFY']
            file_names = modify_df['file_name'].value_counts().index.to_list()
            info = []
            for file_name in file_names:
                last_access_step = ''
                last_modify_step = ''
                creation_step = ''
                if df[(df['file_name'] == file_name) & (df['event_name'] == 'MODIFY')].shape[0] == 0: continue
                last_modify_index = df[(df['file_name'] == file_name) & (df['event_name'] == 'MODIFY')].index.to_list()[-1]
                last_access_index = 0
                if df[(df['file_name'] == file_name) & (df['event_name'] == 'ACCESS')].shape[0] > 0:
                    last_access_index = df[(df['file_name'] == file_name) & (df['event_name'] == 'ACCESS')].index.to_list()[-1]
                else:
                    last_access_index = -1
                    last_access_step = 'Not provided'
                if last_access_index < last_modify_index:
                    try:
                        creation_index = df[(df['file_name'] == file_name) & (df['event_name'] == 'CREATE')].index.to_list()[0]
                    except:
                        creation_index = -1
                        creation_step = 'Not provided'
                    for touch_file_name, (starting_index, ending_index) in steps.items():
                        if (last_access_index > starting_index) & (last_access_index < ending_index):
                            last_access_step = touch_file_name if touch_file_name == 'setup' else touch_file_name.split('_')[1]
                        if (last_modify_index > starting_index) & (last_modify_index < ending_index):
                            last_modify_step = touch_file_name if touch_file_name == 'setup' else touch_file_name.split('_')[1]
                        if (creation_index > starting_index) & (creation_index < ending_index):
                            creation_step = touch_file_name if touch_file_name == 'setup' else touch_file_name.split('_')[1]
                    info.append({'file_name': file_name, 'last_access_index': last_access_index, 'last_modify_index': last_modify_index, 'creation_index': creation_index, 'last_access_step':last_access_step , 'last_modify_step':last_modify_step, 'creation_step': creation_step})
            info_df = pd.DataFrame(info)
            info_df.to_csv('/home/runner/info.csv')
            os.mkdir('optimizing-ci-builds-ci-analysis')
            info_df.to_csv('/home/runner/work/armeria/armeria/optimizing-ci-builds-ci-analysis/analysis.csv')
      - name: Pushes analysis to another repository
        id: push_directory
        uses: cpina/github-action-push-to-another-repository@main
        env:
          API_TOKEN_GITHUB: ${{ secrets.API_TOKEN_GITHUB }}
        with:
          source-directory: 'optimizing-ci-builds-ci-analysis'
          destination-github-username: 'optimizing-ci-builds'
          destination-repository-name: 'ci-analyzes'
          target-directory: 'armeria/.github/workflows/actions_build/flaky-tests'
      - run: touch starting_flaky-tests_actionscheckout@v2_245
      - uses: actions/checkout@v2

      - id: setup-jdk-17
        name: Set up JDK 17
        uses: actions/setup-java@v2
        with:
          distribution: 'temurin'
          java-version: '17'

      - run: touch starting_flaky-tests_Runflakytests_254
      - name: Run flaky tests
        run: |
          ./gradlew --no-daemon --stacktrace --max-workers=2 --parallel check -PnoWeb -PnoLint -PflakyTests=true

      - run: touch starting_flaky-tests_Summarizethefailedtests_258
      - name: Summarize the failed tests
        if: failure()
        run: |
          ./gradlew --no-daemon --stacktrace --max-workers=1 -PnoWeb -PnoLint reportFailedTests
          
          SUMMARY_FILE="build/failed-tests-result.txt"
          if test -f "$SUMMARY_FILE"; then
            echo '#### ðŸ”´ Failed tests' >> $GITHUB_STEP_SUMMARY
            cat $SUMMARY_FILE >> $GITHUB_STEP_SUMMARY
          fi
        shell: bash

      - run: touch starting_flaky-tests_Cleanupthecache_270
      - name: Clean up the cache
        run: |
          rm -fr ~/.gradle/caches/[0-9]* || true
          rm -fr ~/.gradle/caches/journal-* || true
          rm -fr ~/.gradle/caches/transforms-* || true
          rm -f ~/.gradle/caches/*/*.lock || true
          rm -f ~/.gradle/caches/*/gc.properties || true
        shell: bash

      - run: touch starting_flaky-tests_Dumpstuckthreads_279
      - name: Dump stuck threads
        if: always()
        run: jps | grep -vi "jps" | awk '{ print $1 }' | xargs -I'{}' jstack -l {} || true
        shell: bash

